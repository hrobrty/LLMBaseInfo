# day01AGI
## 开营仪式
开营前半个小时 班主任老师进行讲解
## 个人介绍
汇视威-智学优课-漠北老师:

    前高级大数据工程师  xx数据处理中心负责人

    现AI大模型工程师  汇视威-智学优课-VIP讲师

## 学员画像分析调研
1、是否有python编程基础？  需要建立python基础答疑群
2、是否安装大模型前置学习工具？ Anaconda、python(建议安装3.10以上) pycharm(专业版 社区版) 
### 3、学习大模型想要满足的核心需求是什么？
## AI学习方法论
+ 远程工具下载地址:

「建议安装」Todesk下载地址:https://www.todesk.com/ 
## 课程整体介绍
## 其他问题补充与笔记
day01AGI.ipynb 通过pycharm都可以打开的 
## 大模型的初尝
### DeepSeek：小而美



首先来说说DeepSeek，这个模型就像是AI界的“技术宅”，虽然名气不大，但实力绝对不容小觑。它的特点主要有几个：

轻量化：模型体积小，运行速度快，特别适合手机端和低配设备。用起来感觉就像“小而美”的代表，特别适合追求效率的小伙伴。

精准度高：在特定任务上，比如文案生成、代码辅助，DeepSeek的表现简直惊艳，有时候甚至比那些大厂模型还要强。

开源友好：技术文档和API都写得特别清楚，对开发者来说简直是福音。如果你自己搞个小项目，用DeepSeek绝对是个不错的选择。

总结：DeepSeek就像是个低调的学霸，不张扬但实力在线，适合追求效率和精准度！



### 阿里通义千问：潮人玩家 



阿里通义千问，这个模型就像是个“潮人”，总喜欢搞点新花样：

多模态能力：不仅能处理文字，还能玩转图片、视频，简直是AI界的“跨界达人”。

互动性强：聊天时特别会“撩”，用户体验感拉满，适合喜欢新鲜感的你。

技术前沿：经常推出新功能，但偶尔也会有点小bug，适合喜欢尝鲜的你！

总结：阿里通义千问就像是个爱折腾的潮人，有趣但偶尔不靠谱，适合追求新鲜感



### 百度千帆：全能选手



这个模型就像是AI界的“全能选手”，啥都能干，但有时候也显得有点“笨重”：

功能全面：聊天、写诗、翻译、编程……样样精通，堪称AI界的“瑞士军刀”。

商业化成熟：已经广泛应用在各大产品中，技术稳定但创新性稍显不足。

总结：千帆是个经验丰富的老大哥，靠谱但有点“老派”，适合追求稳定性





### 腾讯混元：实干家

这个模型就像是个“实干家”，专注于垂直领域：

行业深耕：在医疗、法律、金融等领域表现突出，特别适合专业人士使用。

数据安全：特别注重隐私保护，用起来更放心。

定制化强：可以根据需求定制模型，但门槛较高，适合企业用户。

总结：腾讯混元就像是个低调的实干家，专业但不够亲民，适合有特定需求
### DeepSeek
官网：https://www.deepseek.com/

模型发展

    2023年11月，DeepSeek Coder推出，专注于代码生成任务，为开发者提供高效、准确的代码建议和解决方案，极大地提升了软件开发的效率。

    随后，DeepSeek LLM亮相，具备强大的语言理解和生成能力，在自然语言处理的多个任务中表现出色。

    2024年，DeepSeek推出V2版本，在架构层面进行创新，提出MLA（Multi-head Latent Attention，多头潜在注意力机制）架构，优化了显存占用和计算量，提升了运行效率和性能。

    2024年12月发布的DeepSeek-V3，拥有高达6710亿个参数，训练成本为558万美元，在多项权威评测中性能卓越，与GPT-4o和Claude 3.5 Sonnet等顶尖模型相媲美。

    2025年1月，DeepSeek又推出R1版本，采用纯深度学习的方法让AI自发涌现出推理能力，在数学、代码、自然语言推理等任务上性能比肩OpenAI o1模型正式版，且训练成本仅为560万美元。



核心特点

    推理能力强：DeepSeek特别强化了推理能力，通过强化学习等先进技术，能够深入理解和创新。

    理解自然：与传统的指令模型相比，DeepSeek更易于理解和沟通，不需要复杂的提示词。

    深度思考：能够进行推理、批判性思考，适用于行业分析、决策支持等高阶场景。

    高性价比：DeepSeek在成本控制上表现出色，通过优化训练方式降低了成本，使得更多的研究机构和企业能够负担得起模型的训练和应用。

    完全开源：DeepSeek将模型代码和训练细节完全公开，允许全球开发者自由获取、修改和优化，促进了AI开发者社区的协作生态。



应用场景

    DeepSeek应用广泛，涵盖智能对话、文本生成、语义理解等多个领域。

    支持联网搜索和深度思考模式，能处理文件上传，读取文件及图片文字内容。

    具体应用包括文本创作、自然语言理解、编程代码相关、绘图等。
from openai import OpenAI



client = OpenAI(api_key="sk-e9f88d6b5e3b42e5b0786120dee7d390", base_url="https://api.deepseek.com")

response = client.chat.completions.create(

    model="deepseek-chat",

    messages=[

        {"role": "system", "content": "你是一个乐于助人的ai助手"},

        {"role": "user", "content": "你好,你是谁"},

    ],

    stream=False

)

print(response.choices[0].message.content)
from openai import OpenAI

from dotenv import load_dotenv

import os

#加载环境变量中的.env文件

load_dotenv()  

# api_key=os.getenv('DEEPSEEK_API_KEY')

# base_url=os.getenv('DEEPSEEK_BASE_URL')

# print(api_key)

#创建OpenAI的客户端

# client = OpenAI()  #兼容OpenAI的api



client = OpenAI(api_key=api_key, base_url=base_url)

response = client.chat.completions.create(

    model="deepseek-chat",

    #用来与ai回话的提示词

    messages=[

        {"role": "system", "content": "你是一个乐于助人的AI"},

        {"role": "user", "content": "你背后是什么模型"},

    ],

    stream=False

)

# print(response)

print(response.choices[0].message.content)

#### load_dotenv()解释

load_dotenv函数的主要功能是读取并加载.env文件中的内容，将这些内容作为环境变量添加到当前运行的Python进程的环境中。



可以通过os.getenv('VARIABLE_NAME')来访问.env文件中的变量。
from openai import OpenAI

from dotenv import load_dotenv

load_dotenv()

#创建OpenAI的客户端

client = OpenAI()

#创建对话

response = client.chat.completions.create(

    model="deepseek-chat",

    messages = [

         {'role': 'system','content': '你是一个故事专家,为用户提供丰富的故事'},

         {'role': 'user','content': '讲一个司马光砸缸的故事'},

    ]

)

# print(response)

print(response.choices[0].message.content)
#### 模型

deepseek-chat

是专注于自然语言对话的模型，主要用于生成和理解人类语言，适用于聊天机器人、客服系统等场景。



deepseek-reasoner

是DeepSeek平台上线的一款专注于推理的AI模型。与普通的聊天模型（如deepseek-chat）相比，deepseek-reasoner更适合进行深度推理、决策支持等复杂场景的任务。



#### messages 用于对话系统中,表示对话的上下文。



messages 是一个列表，每个元素是一个字典对象，包含以下两个关键字段：

    role：指示消息的发送者，可以是 "system"、"user" 或 "assistant"。

    content：消息的内容，即实际的文本。



role 的具体含义:



system:

    用于设定模型的行为或提供上下文指导。

    通常在对话开始时使用，用于定义模型的角色、语气或背景信息。

user:

    用户的输入或问题。

    表示对话中用户发言的内容。

assistant:

    模型的回复。

    表示模型在对话中生成的内容。
from openai import OpenAI

from dotenv import load_dotenv

load_dotenv()

client = OpenAI()

response = client.chat.completions.create(

    model="deepseek-chat",

    messages = [

         {'role': 'system','content': '你是一个作家，有着良好的文学修养，擅长撰写各类文章'},

         {'role': 'user','content': '写一篇100字左右的随笔'},

    ],

    stream=False

)

print(response.choices[0].message.content)
from openai import OpenAI

from dotenv import load_dotenv

load_dotenv()

client = OpenAI()

response = client.chat.completions.create(

    model='deepseek-chat',

    messages = [

         {'role': 'system','content': '你是一个在线翻译，翻译用户指定的内容为{language}'}, #提供AI的角色

         {'role': 'user','content': '你在吗？今天外面的天气真好呀，出来玩呀','language':'英语'},

    ],

    stream=False  #是否以流式的形式响应，可以省略不写默认是False

)

print(response.choices[0].message.content)
from openai import OpenAI

from dotenv import load_dotenv

load_dotenv()

client = OpenAI()

prompt = '''

这组数字中奇数加起来的结果是个偶数：10,3,5,20,1,7,40

答案是真还是假

'''

response = client.chat.completions.create(

    model='deepseek-chat',

    messages = [

         {'role': 'user','content': prompt}, #直接询问的方式

    ],

)

print(response.choices[0].message.content)

方式二:
from langchain_openai import ChatOpenAI

from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(

    model='deepseek-chat',

    max_tokens=1024,

    temperature=1.3

)

response = llm.invoke("给我一个很土但是听起来很好养活的男孩小名")

print(response.content)
ChatOpenAI



用途: ChatOpenAI 通常用于与聊天模型进行交互，适合处理对话式任务。



适用场景: 适合需要生成对话或连续文本的任务，如聊天机器人、对话生成等。
用途: OpenAI 是一个更通用的客户端，用于与 OpenAI 的各种 API 进行交互，包括但不限于聊天模型、文本生成、图像生成等。



总结:

ChatOpenAI 专注于聊天模型的交互，适合对话式任务。

OpenAI 是一个更通用的客户端，适合多种 OpenAI 服务的调用。
### 通义千问大模型
官网：https://www.aliyun.com/product/bailian

      通义千问是阿里云推出的一系列大规模预训练语言模型，旨在提供强大的自然语言理解和生成能力。这些模型能够处理多种任务，包括但不限于文字创作、文本处理、编程辅助、翻译服务、对话模拟以及数据可视化等。



特点：



1. **多版本模型**：通义千问提供了不同规模和功能的多个版本，以适应不同的应用场景和需求。其中包括：

   - **通义千问-Max**：该系列中性能最好的模型，适合复杂、多步骤的任务。

   - **通义千问-Plus**：在推理效果、成本和速度之间取得平衡，适合中等复杂度的任务。

   - **通义千问-Turbo**：速度最快、成本最低的模型，适用于简单任务。

   - **Qwen2.5**：涵盖多个尺寸的大语言模型、多模态模型、数学模型和代码模型，旗舰模型号称性能超越Llama 405B。



2. **技术特点**：通义千问模型采用了先进的深度学习技术，如Transformer架构，并经过大量的文本数据进行预训练，

使其能够理解并生成高质量的自然语言内容。此外，通过使用人类反馈强化学习（RLHF）等技术对模型进行微调，

提高了模型与用户交互的质量。



3. **多语言支持**：通义千问不仅支持中文，还支持其他多种语言，包括英文、法文、西班牙文、俄文、日文等，

这使得它在全球范围内都有广泛的应用潜力。



4. **开源与商业化**：部分通义千问模型已经开源，允许开发者自由地探索和使用这些模型的能力。同时，

也有商业版提供给需要更高级别支持和服务的企业客户。



5. **应用场景**：由于其强大的语言理解和生成能力，通义千问被应用于众多领域，如教育、娱乐、金融、医疗保健等，为用户提供智能客服、内容生成、数据分析等多种服务。



6. **持续更新**：随着时间的发展，阿里云不断优化和升级通义千问模型，提高其性能、准确性和适用性，确保用户能获得最新和最佳的服务体验。
from openai import OpenAI

from dotenv import load_dotenv

load_dotenv()

client = OpenAI()

completion = client.chat.completions.create(

    model="qwen-plus",  # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models

    messages=[

        {'role': 'system', 'content': '你是一个功能强大的AI，可以给用户提出的问题提供高质量的回复'},

        {'role': 'user', 'content': '今天长沙的天气怎么样'}],

)

# print(completion.model_dump_json())

print(completion.choices[0].message)
方式二
from langchain_openai import ChatOpenAI

from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(

    model='qwen-plus',

)

response = llm.invoke("给我一个是听起来很文艺的男生花名")

print(response.content)